{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d3f93b03",
      "metadata": {
        "id": "d3f93b03"
      },
      "source": [
        "\n",
        "# Chapter 11: Training Deep Neural Networks\n",
        "\n",
        "## 1. Pendahuluan\n",
        "\n",
        "Bab ini membahas bagaimana melatih jaringan saraf dalam (Deep Neural Networks / DNNs) secara efisien dan stabil. Kita akan belajar mengatasi masalah seperti **vanishing gradients**, **exploding gradients**, serta mengenal teknik-teknik seperti **Batch Normalization**, **Dropout**, dan **Advanced Optimizers**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9084fdd8",
      "metadata": {
        "id": "9084fdd8"
      },
      "source": [
        "\n",
        "## 2. Vanishing & Exploding Gradients\n",
        "\n",
        "### üîç Permasalahan\n",
        "\n",
        "- **Vanishing gradients**: Gradien mengecil seiring berjalannya backpropagation ‚Üí pembelajaran menjadi sangat lambat.\n",
        "- **Exploding gradients**: Gradien membesar ‚Üí bobot menjadi `NaN` atau `inf`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83b3ec45",
      "metadata": {
        "id": "83b3ec45"
      },
      "source": [
        "\n",
        "## 3. Inisialisasi Bobot yang Tepat\n",
        "\n",
        "### Glorot/Xavier Initialization\n",
        "\n",
        "Untuk menghindari masalah gradien, digunakan inisialisasi sebagai berikut:\n",
        "\n",
        "$$ Var[w] = \\frac{2}{n_{in} + n_{out}} $$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a21466e",
      "metadata": {
        "id": "8a21466e"
      },
      "outputs": [],
      "source": [
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "layer = keras.layers.Dense(100, activation=\"relu\",\n",
        "                           kernel_initializer=\"glorot_uniform\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "754c29ca",
      "metadata": {
        "id": "754c29ca"
      },
      "source": [
        "\n",
        "## 4. Fungsi Aktivasi Non-Saturasi\n",
        "\n",
        "### ReLU\n",
        "\n",
        "Fungsi aktivasi ReLU:\n",
        "\n",
        "$$ ReLU(x) = \\max(0, x) $$\n",
        "\n",
        "Lebih stabil dibanding sigmoid atau tanh. Variasi lain: `LeakyReLU`, `ELU`, `SELU`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "238c2bb5",
      "metadata": {
        "id": "238c2bb5"
      },
      "source": [
        "\n",
        "## 5. Batch Normalization\n",
        "\n",
        "Batch Normalization mempercepat dan menstabilkan training dengan menormalkan aktivasi intermediate.\n",
        "\n",
        "### Formula:\n",
        "\n",
        "$$ \\hat{x}^{(k)} = \\frac{x^{(k)} - \\mu_B}{\\sqrt{\\sigma_B^2 + \\epsilon}} $$\n",
        "\n",
        "$$ y^{(k)} = \\gamma^{(k)} \\hat{x}^{(k)} + \\beta^{(k)} $$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f7b0a69",
      "metadata": {
        "id": "2f7b0a69"
      },
      "outputs": [],
      "source": [
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Dense(100, activation=\"relu\"),\n",
        "    keras.layers.BatchNormalization()\n",
        "])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af8e00d7",
      "metadata": {
        "id": "af8e00d7"
      },
      "source": [
        "\n",
        "## 6. Gradient Clipping\n",
        "\n",
        "Mencegah exploding gradients dengan membatasi nilai gradien maksimum:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce892782",
      "metadata": {
        "id": "ce892782"
      },
      "outputs": [],
      "source": [
        "\n",
        "optimizer = keras.optimizers.SGD(clipvalue=1.0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9dbd76fb",
      "metadata": {
        "id": "9dbd76fb"
      },
      "source": [
        "\n",
        "## 7. Transfer Learning\n",
        "\n",
        "Gunakan model yang sudah dilatih pada dataset besar:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fab76c6f",
      "metadata": {
        "id": "fab76c6f"
      },
      "outputs": [],
      "source": [
        "\n",
        "base_model = keras.applications.Xception(weights=\"imagenet\",\n",
        "                                         include_top=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1abce78b",
      "metadata": {
        "id": "1abce78b"
      },
      "source": [
        "\n",
        "## 8. Optimizer Cepat\n",
        "\n",
        "| Optimizer | Keunggulan |\n",
        "|----------|-------------|\n",
        "| **Momentum** | Mempercepat konvergensi |\n",
        "| **Nesterov** | Perkiraan lebih akurat |\n",
        "| **RMSProp** | Adaptif terhadap data noisy |\n",
        "| **Adam** | Kombinasi terbaik antara momentum dan RMSProp |\n",
        "\n",
        "### Contoh:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "820528a6",
      "metadata": {
        "id": "820528a6"
      },
      "outputs": [],
      "source": [
        "\n",
        "optimizer = keras.optimizers.Adam()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e30bddd8",
      "metadata": {
        "id": "e30bddd8"
      },
      "source": [
        "\n",
        "## 9. Regularization\n",
        "\n",
        "### Teknik-teknik penting:\n",
        "\n",
        "- **L1 & L2 Regularization**\n",
        "- **Dropout**\n",
        "- **Monte Carlo Dropout**\n",
        "- **Max-Norm Constraint**\n",
        "\n",
        "### Dropout di Keras:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d2384e4",
      "metadata": {
        "id": "2d2384e4"
      },
      "outputs": [],
      "source": [
        "\n",
        "keras.layers.Dropout(rate=0.5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69f30e18",
      "metadata": {
        "id": "69f30e18"
      },
      "source": [
        "\n",
        "## 10. Prinsip Praktis\n",
        "\n",
        "### Checklist:\n",
        "\n",
        "1. Gunakan inisialisasi bobot seperti Glorot atau He.\n",
        "2. Gunakan fungsi aktivasi non-saturasi (ReLU family).\n",
        "3. Terapkan Batch Normalization.\n",
        "4. Gunakan optimizer seperti Adam.\n",
        "5. Tambahkan regularisasi untuk mencegah overfitting.\n",
        "6. Evaluasi dengan data validasi/tes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61c1a8c1",
      "metadata": {
        "id": "61c1a8c1"
      },
      "source": [
        "\n",
        "## üíª Contoh Kode Keras Lengkap\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0bcaf3aa",
      "metadata": {
        "id": "0bcaf3aa"
      },
      "outputs": [],
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.Dense(300, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(100, activation=\"relu\"),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}